{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# XXX parameterize path\n",
    "# import data\n",
    "data = pd.read_csv(\"projects/heart-disease/data/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validate test split\n",
    "def train_val_test_split(df, target, val, test):\n",
    "    \n",
    "    X = df.drop([target], axis=1)\n",
    "    y = df[target]\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=val+test, random_state=42)\n",
    "    \n",
    "    val_test_split = test / (val + test)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_test_split, random_state=42)\n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "    #y_val = y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(data, 'target', 0.2, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count null values\n",
    "def count_nulls(df):\n",
    "    return [df[col].isna().sum() for col in df.columns]\n",
    "\n",
    "\n",
    "# assign quantitative and categorical columns by dtype\n",
    "def assign_col(df):\n",
    "    return ['cat' if df[col].dtype == object else 'quant' if df[col].dtype in [int, float]\n",
    "            else '???' for col in df.columns]\n",
    "\n",
    "\n",
    "# return data types\n",
    "def data_types(df):\n",
    "    return [df[col].dtype for col in df.columns]\n",
    "\n",
    "\n",
    "# return summary statistics\n",
    "def summary_stats(df):\n",
    "    \n",
    "    stats_list = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        stats = \"\"\n",
    "        \n",
    "        if df[col].dtype in [int, float]:\n",
    "            \n",
    "            stats += \"min: \" + str(df[col].min())\n",
    "            stats += \", max: \" + str(df[col].max())\n",
    "            stats += \", mean: \" + str(round(df[col].mean(), 4))\n",
    "            \n",
    "        elif df[col].dtype == object:\n",
    "            \n",
    "            count = df[col].value_counts(sort = True)\n",
    "            percent = df[col].value_counts(normalize = True, sort = True)\n",
    "\n",
    "            values = pd.DataFrame({'count': count, 'percent': percent})\n",
    "\n",
    "            cat_count = count.shape[0]\n",
    "\n",
    "            for i, r in values.iterrows():\n",
    "                stats += \"{0}: {1} {2}%,   \".format(i, r['count'], round(r['percent'] * 100, 2))\n",
    "        \n",
    "        else:\n",
    "            stats = \"not correctly processed based on data type\"\n",
    "            \n",
    "        stats_list.append(stats[:-4])\n",
    "    \n",
    "    return stats_list\n",
    "\n",
    "\n",
    "# assemble all pieces together\n",
    "def summary(df):\n",
    "    \n",
    "    n, m = df.shape[0], df.shape[1]\n",
    "    \n",
    "    print(\"n = {0}, m = {1}\".format(n, m))\n",
    "    \n",
    "    names = df.columns\n",
    "    nulls = count_nulls(df)\n",
    "    assign = assign_col(df)\n",
    "    dtypes = data_types(df)\n",
    "    statistics = summary_stats(df)\n",
    "    \n",
    "    frame = {'Column Name': names, 'Null Count': nulls, 'Data Assign': assign,\n",
    "             'Data Type': dtypes, 'Summary Stats': statistics}\n",
    "    \n",
    "    print(tabulate(pd.DataFrame(frame), headers='keys', tablefmt='psql'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 303, m = 14\n",
      "+----+---------------+--------------+---------------+-------------+-------------------------------+\n",
      "|    | Column Name   |   Null Count | Data Assign   | Data Type   | Summary Stats                 |\n",
      "|----+---------------+--------------+---------------+-------------+-------------------------------|\n",
      "|  0 | age           |            0 | quant         | int64       | min: 29, max: 77, mean: 54.   |\n",
      "|  1 | sex           |            0 | quant         | int64       | min: 0, max: 1, mean: 0.      |\n",
      "|  2 | cp            |            0 | quant         | int64       | min: 0, max: 3, mean: 0       |\n",
      "|  3 | trestbps      |            0 | quant         | int64       | min: 94, max: 200, mean: 131. |\n",
      "|  4 | chol          |            0 | quant         | int64       | min: 126, max: 564, mean: 246 |\n",
      "|  5 | fbs           |            0 | quant         | int64       | min: 0, max: 1, mean: 0.      |\n",
      "|  6 | restecg       |            0 | quant         | int64       | min: 0, max: 2, mean: 0.      |\n",
      "|  7 | thalach       |            0 | quant         | int64       | min: 71, max: 202, mean: 149. |\n",
      "|  8 | exang         |            0 | quant         | int64       | min: 0, max: 1, mean: 0.      |\n",
      "|  9 | oldpeak       |            0 | quant         | float64     | min: 0.0, max: 6.2, mean: 1.  |\n",
      "| 10 | slope         |            0 | quant         | int64       | min: 0, max: 2, mean: 1.      |\n",
      "| 11 | ca            |            0 | quant         | int64       | min: 0, max: 4, mean: 0.      |\n",
      "| 12 | thal          |            0 | quant         | int64       | min: 0, max: 3, mean: 2.      |\n",
      "| 13 | target        |            0 | quant         | int64       | min: 0, max: 1, mean: 0.      |\n",
      "+----+---------------+--------------+---------------+-------------+-------------------------------+\n"
     ]
    }
   ],
   "source": [
    "summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 196, m = 13\n",
      "+----+---------------+--------------+---------------+-------------+--------------------------------+\n",
      "|    | Column Name   |   Null Count | Data Assign   | Data Type   | Summary Stats                  |\n",
      "|----+---------------+--------------+---------------+-------------+--------------------------------|\n",
      "|  0 | age           |            0 | quant         | int64       | min: 34, max: 77, mean: 54.    |\n",
      "|  1 | sex           |            0 | quant         | int64       | min: 0, max: 1, mean: 0.       |\n",
      "|  2 | cp            |            0 | quant         | int64       | min: 0, max: 3, mean: 1.       |\n",
      "|  3 | trestbps      |            0 | quant         | int64       | min: 94, max: 192, mean: 131.  |\n",
      "|  4 | chol          |            0 | quant         | int64       | min: 131, max: 564, mean: 248. |\n",
      "|  5 | fbs           |            0 | quant         | int64       | min: 0, max: 1, mean: 0.       |\n",
      "|  6 | restecg       |            0 | quant         | int64       | min: 0, max: 2, mean: 0.       |\n",
      "|  7 | thalach       |            0 | quant         | int64       | min: 88, max: 195, mean: 149.  |\n",
      "|  8 | exang         |            0 | quant         | int64       | min: 0, max: 1, mean: 0.       |\n",
      "|  9 | oldpeak       |            0 | quant         | float64     | min: 0.0, max: 5.6, mean: 1.   |\n",
      "| 10 | slope         |            0 | quant         | int64       | min: 0, max: 2, mean: 1        |\n",
      "| 11 | ca            |            0 | quant         | int64       | min: 0, max: 3, mean: 0.       |\n",
      "| 12 | thal          |            0 | quant         | int64       | min: 0, max: 3, mean: 2.       |\n",
      "+----+---------------+--------------+---------------+-------------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "summary(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "def check_nulls(col_list, df):\n",
    "    return [col for col in col_list if df[col].isna().sum() > 1]\n",
    "\n",
    "\n",
    "# fill null values\n",
    "def categorical_nulls(col_list, df):\n",
    "    for col in col_list:\n",
    "        df[col] = df[col].fillna('NA')\n",
    "\n",
    "def quantitative_nulls(col_list, df):\n",
    "    for col in col_list:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "\n",
    "# \n",
    "# def baseline(df):\n",
    "    \n",
    "#     cat = categorical_columns(df)\n",
    "#     quant = quantitative_columns(df)\n",
    "    \n",
    "#     # no nulls\n",
    "#     cat_nulls = check_nulls(cat, df)\n",
    "#     quant_nulls = check_nulls(quant, df)\n",
    "    \n",
    "#     categorical_nulls(cat_nulls, df)\n",
    "#     quantitative_nulls(quant_nulls, df)\n",
    "    \n",
    "#     df = create_dummies(cat, df)\n",
    "    \n",
    "#     return df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove item from a set without throwing an error\n",
    "# if it does not exist\n",
    "def remove_safe(lst, value):\n",
    "    try:\n",
    "        lst.remove(value)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    return lst\n",
    "\n",
    "\n",
    "# identify quantitative and categorical columns by dtype\n",
    "def detect_col_type(df):\n",
    "    cat = {col for col in df if df[col].dtype == object}\n",
    "    quant = {col for col in df if df[col].dtype in [int, float]}\n",
    "    \n",
    "    return [cat, quant]\n",
    "\n",
    "\n",
    "# create dummies for categorical variables\n",
    "def create_dummies(col_list, df):\n",
    "    \n",
    "    df_extend = df.copy()\n",
    "    \n",
    "    # if the column contains values outside of 0 and 1\n",
    "    #col_list = [col for col in col_list if df[col] not in [0, 1]]\n",
    "    \n",
    "    for col in col_list:\n",
    "        dummies = pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True)\n",
    "        df_extend = pd.concat([df_extend, dummies], axis=1, sort=True).drop(labels=col, axis=1)\n",
    "    \n",
    "    return df_extend\n",
    "\n",
    "\n",
    "def ReconcileSplits(X_t, X_v):\n",
    "    \n",
    "    in_train_not_val = [col for col in X_t.columns if col not in X_v.columns]\n",
    "    in_val_not_train = [col for col in X_v.columns if col not in X_t.columns]\n",
    "    \n",
    "    new_cats = []\n",
    "    \n",
    "    for col in in_train_not_val:\n",
    "        X_v[col] = 0\n",
    "    \n",
    "    for col in in_val_not_train:\n",
    "        new_cats.append([col, X_v[col].sum()])\n",
    "        X_v = X_v.drop([col], axis=1)\n",
    "    \n",
    "    # ensure the same column order\n",
    "    X_v = X_v[X_t.columns]\n",
    "    \n",
    "    return [X_v, new_cats]\n",
    "\n",
    "#     return [in_train_not_val, in_val_not_train]\n",
    "\n",
    "\n",
    "# \n",
    "def baseline(df, assign = None):\n",
    "    \n",
    "    cat, quant = detect_col_type(df)\n",
    "    \n",
    "    if type(assign) == dict:\n",
    "        \n",
    "        for item in assign.items():\n",
    "            if item[1] == 'cat':\n",
    "                quant = remove_safe(quant, item[0])\n",
    "                cat.add(item[0])\n",
    "            elif item[1] == 'quant':\n",
    "                cat = remove_safe(cat, item[0])\n",
    "                quant.add(item[0])\n",
    "            else:\n",
    "                raise Exception(\"column must be assigned to 'cat' or 'quant'\")\n",
    "    \n",
    "#     # no nulls\n",
    "#     cat_nulls = check_nulls(cat, df)\n",
    "#     quant_nulls = check_nulls(quant, df)\n",
    "    \n",
    "#     categorical_nulls(cat_nulls, df)\n",
    "#     quantitative_nulls(quant_nulls, df)\n",
    "    \n",
    "    df = create_dummies(cat, df)\n",
    "    \n",
    "    return df #df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "# manage splits through transformations\n",
    "def baseline_train_val_test(X_t, X_v, X_te, assign):\n",
    "    \n",
    "    X_t = baseline(X_t, assign)\n",
    "    X_v = baseline(X_v, assign)\n",
    "    X_te = baseline(X_te, assign)\n",
    "    \n",
    "    X_v, v_drop = ReconcileSplits(X_t, X_v)\n",
    "    X_te, te_drop = ReconcileSplits(X_t, X_te)\n",
    "    \n",
    "    \n",
    "    return [X_t, X_v, X_te, v_drop, te_drop]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_columns = {'sex': 'cat', 'cp': 'cat', 'fbs': 'cat', 'restecg': 'cat', 'exang': 'cat',\n",
    "                'slope': 'cat', 'ca': 'cat', 'thal': 'cat'}\n",
    "\n",
    "X_t, X_v, X_te, v_drop, te_drop = baseline_train_val_test(X_train, X_val, X_test, map_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ca_4', 1]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ca_4', 4]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 196, m = 13\n",
      "+----+---------------+--------------+---------------+-------------+--------------------------------+\n",
      "|    | Column Name   |   Null Count | Data Assign   | Data Type   | Summary Stats                  |\n",
      "|----+---------------+--------------+---------------+-------------+--------------------------------|\n",
      "|  0 | age           |            0 | quant         | int64       | min: 34, max: 77, mean: 54.    |\n",
      "|  1 | sex           |            0 | quant         | int64       | min: 0, max: 1, mean: 0.       |\n",
      "|  2 | cp            |            0 | quant         | int64       | min: 0, max: 3, mean: 1.       |\n",
      "|  3 | trestbps      |            0 | quant         | int64       | min: 94, max: 192, mean: 131.  |\n",
      "|  4 | chol          |            0 | quant         | int64       | min: 131, max: 564, mean: 248. |\n",
      "|  5 | fbs           |            0 | quant         | int64       | min: 0, max: 1, mean: 0.       |\n",
      "|  6 | restecg       |            0 | quant         | int64       | min: 0, max: 2, mean: 0.       |\n",
      "|  7 | thalach       |            0 | quant         | int64       | min: 88, max: 195, mean: 149.  |\n",
      "|  8 | exang         |            0 | quant         | int64       | min: 0, max: 1, mean: 0.       |\n",
      "|  9 | oldpeak       |            0 | quant         | float64     | min: 0.0, max: 5.6, mean: 1.   |\n",
      "| 10 | slope         |            0 | quant         | int64       | min: 0, max: 2, mean: 1        |\n",
      "| 11 | ca            |            0 | quant         | int64       | min: 0, max: 3, mean: 0.       |\n",
      "| 12 | thal          |            0 | quant         | int64       | min: 0, max: 3, mean: 2.       |\n",
      "+----+---------------+--------------+---------------+-------------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "summary(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neural_network.multilayer_perceptron module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neural_network. Anything that cannot be imported from sklearn.neural_network is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.stochastic_gradient module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.ridge module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.passive_aggressive module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.gaussian_process.gpc module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.gaussian_process. Anything that cannot be imported from sklearn.gaussian_process is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.weight_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.gradient_boosting module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "#from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors.classification import KNeighborsClassifier\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier ###\n",
    "from sklearn.linear_model.ridge import RidgeClassifierCV\n",
    "from sklearn.linear_model.ridge import RidgeClassifier\n",
    "from sklearn.linear_model.passive_aggressive import PassiveAggressiveClassifier    \n",
    "from sklearn.gaussian_process.gpc import GaussianProcessClassifier\n",
    "#from sklearn.ensemble.voting_classifier import VotingClassifier\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "#from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
    "from sklearn.ensemble.forest import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "#from sklearn.naive_bayes import MultinomialNB  \n",
    "#from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.svm import NuSVC\n",
    "### from sklearn.linear_model import Perceptron\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import issue\n",
    "# from sklearn.mixture import DPGMM\n",
    "# from sklearn.mixture import GMM \n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# from sklearn.mixture import VBGMM\n",
    "\n",
    "\n",
    "# from sklearn.multiclass import OutputCodeClassifier\n",
    "# from sklearn.multiclass import OneVsOneClassifier\n",
    "# from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [['kNN', {'n_neighbors': [3,5,7,9], 'weights': ['uniform', 'distance'],\n",
    "                                                'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'p': [1,2,3]}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: k=3, weights=uniform, algorithm=auto, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=uniform, algorithm=auto, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=uniform, algorithm=auto, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=3, weights=uniform, algorithm=ball_tree, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=uniform, algorithm=ball_tree, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=uniform, algorithm=ball_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=3, weights=uniform, algorithm=kd_tree, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=uniform, algorithm=kd_tree, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=uniform, algorithm=kd_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=3, weights=uniform, algorithm=brute, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=uniform, algorithm=brute, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=uniform, algorithm=brute, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=3, weights=distance, algorithm=auto, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=distance, algorithm=auto, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=distance, algorithm=auto, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=3, weights=distance, algorithm=ball_tree, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=distance, algorithm=ball_tree, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=distance, algorithm=ball_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=3, weights=distance, algorithm=kd_tree, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=distance, algorithm=kd_tree, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=distance, algorithm=kd_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=3, weights=distance, algorithm=brute, p=1\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=3, weights=distance, algorithm=brute, p=2\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=3, weights=distance, algorithm=brute, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=uniform, algorithm=auto, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=uniform, algorithm=auto, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=uniform, algorithm=auto, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=5, weights=uniform, algorithm=ball_tree, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=uniform, algorithm=ball_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=uniform, algorithm=ball_tree, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=5, weights=uniform, algorithm=kd_tree, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=uniform, algorithm=kd_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=uniform, algorithm=kd_tree, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=5, weights=uniform, algorithm=brute, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=uniform, algorithm=brute, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=uniform, algorithm=brute, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=5, weights=distance, algorithm=auto, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=distance, algorithm=auto, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=distance, algorithm=auto, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=5, weights=distance, algorithm=ball_tree, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=distance, algorithm=ball_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=distance, algorithm=ball_tree, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=5, weights=distance, algorithm=kd_tree, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=distance, algorithm=kd_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=distance, algorithm=kd_tree, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=5, weights=distance, algorithm=brute, p=1\n",
      "Accuracy: 72.13%, Log Loss: 9.626\n",
      "Parameters: k=5, weights=distance, algorithm=brute, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=5, weights=distance, algorithm=brute, p=3\n",
      "Accuracy: 60.66%, Log Loss: 13.59\n",
      "Parameters: k=7, weights=uniform, algorithm=auto, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=uniform, algorithm=auto, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=uniform, algorithm=auto, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=7, weights=uniform, algorithm=ball_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=uniform, algorithm=ball_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=uniform, algorithm=ball_tree, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=7, weights=uniform, algorithm=kd_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=uniform, algorithm=kd_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=uniform, algorithm=kd_tree, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=7, weights=uniform, algorithm=brute, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=uniform, algorithm=brute, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=uniform, algorithm=brute, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=7, weights=distance, algorithm=auto, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=distance, algorithm=auto, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=distance, algorithm=auto, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=7, weights=distance, algorithm=ball_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=distance, algorithm=ball_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=distance, algorithm=ball_tree, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=7, weights=distance, algorithm=kd_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=distance, algorithm=kd_tree, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=distance, algorithm=kd_tree, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=7, weights=distance, algorithm=brute, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=7, weights=distance, algorithm=brute, p=2\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=7, weights=distance, algorithm=brute, p=3\n",
      "Accuracy: 67.21%, Log Loss: 11.32\n",
      "Parameters: k=9, weights=uniform, algorithm=auto, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=uniform, algorithm=auto, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=uniform, algorithm=auto, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=9, weights=uniform, algorithm=ball_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=uniform, algorithm=ball_tree, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=uniform, algorithm=ball_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=9, weights=uniform, algorithm=kd_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=uniform, algorithm=kd_tree, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=uniform, algorithm=kd_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=9, weights=uniform, algorithm=brute, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=uniform, algorithm=brute, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=uniform, algorithm=brute, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=9, weights=distance, algorithm=auto, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=distance, algorithm=auto, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=distance, algorithm=auto, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=9, weights=distance, algorithm=ball_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=distance, algorithm=ball_tree, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=distance, algorithm=ball_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=9, weights=distance, algorithm=kd_tree, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=distance, algorithm=kd_tree, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=distance, algorithm=kd_tree, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n",
      "Parameters: k=9, weights=distance, algorithm=brute, p=1\n",
      "Accuracy: 65.57%, Log Loss: 11.89\n",
      "Parameters: k=9, weights=distance, algorithm=brute, p=2\n",
      "Accuracy: 62.30%, Log Loss: 13.02\n",
      "Parameters: k=9, weights=distance, algorithm=brute, p=3\n",
      "Accuracy: 63.93%, Log Loss: 12.46\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    \n",
    "    for k in classifier[1]['n_neighbors']:\n",
    "        for weights in classifier[1]['weights']:\n",
    "            for algorithm in classifier[1]['algorithm']:\n",
    "                for p in classifier[1]['p']:\n",
    "                    \n",
    "                    model = KNeighborsClassifier(n_neighbors=k, weights=weights, algorithm=algorithm, p=p)\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "                    y_pred = model.predict(X_val)\n",
    "                    \n",
    "                    # parameterize what you want to evaluate / see\n",
    "                    #print(classification_report(y_val, y_pred))\n",
    "                    print('Parameters: k={}, weights={}, algorithm={}, p={}'.format(k, weights, algorithm, p))\n",
    "                    print('Accuracy: {:.2%}, Log Loss: {:.4}'.format(accuracy_score(y_val, y_pred), log_loss(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Parameters: k=5, weights=uniform, algorithm=auto, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "Parameters: k=5, weights=uniform, algorithm=ball_tree, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "Parameters: k=5, weights=uniform, algorithm=kd_tree, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "Parameters: k=5, weights=uniform, algorithm=brute, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "Parameters: k=5, weights=distance, algorithm=auto, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "Parameters: k=5, weights=distance, algorithm=ball_tree, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "Parameters: k=5, weights=distance, algorithm=kd_tree, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "Parameters: k=5, weights=distance, algorithm=brute, p=1\n",
    "Accuracy: 72.13%, Log Loss: 9.626\n",
    "\n",
    "\n",
    "Clear winners\n",
    "k = 5\n",
    "p = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ScaleTest(X_t, y_t, X_v, y_v):\n",
    "    \n",
    "#     scales = [('Not Scaled/Normalized', np.nan), ('MaxAbsScaler', pp.MaxAbsScaler()), ('MinMaxScaler', pp.MinMaxScaler()),\n",
    "#               ('L1 Normalizer', pp.Normalizer(norm='l1')), ('L2 Normalizer', pp.Normalizer(norm='l2')),\n",
    "#               ('PowerTransformer', pp.PowerTransformer()), ('Uniform QuantileTransformer', pp.QuantileTransformer(output_distribution='uniform')),\n",
    "#               ('Normal QuantileTransformer', pp.QuantileTransformer(output_distribution='normal')), ('RobustScaler', pp.RobustScaler()),\n",
    "#               ('StandardScaler', pp.StandardScaler())]\n",
    "    \n",
    "#     for scaler in scales:\n",
    "        \n",
    "#         X_t_scale = X_t\n",
    "#         X_v_scale = X_v\n",
    "        \n",
    "#         if scaler[0] != 'Not Scaled/Normalized':\n",
    "#             X_t_scale = Scale(X_t, scaler[1])\n",
    "#             X_v_scale = Scale(X_v, scaler[1])\n",
    "        \n",
    "#         reg = LinearRegression()\n",
    "#         reg.fit(X_t_scale, y_t)\n",
    "\n",
    "#         y_p = reg.predict(X_v_scale)\n",
    "        \n",
    "#         print('\\n' + scaler[0])\n",
    "#         LREvaluate(y_v, y_p, X_v_scale.shape[1])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train['sex'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train['sex'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train['sex'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
